---
title: Some Thoughts on AI
description: A congelation of ideas from the last two years of working with AI
---
AI knowledge-management tools like [NotebookLM](https://notebooklm.google/) and [ZenFetch](https://zenfetch.com/) seem like they could be useful. But, on the other hand, they remind me that I have an LLM of my own between my ears and should probably [put stuff into that](https://www.henrikkarlsson.xyz/p/training-data) instead of into fancy tech products, so that I can understand things myself instead of relying on an LLM to understand for me.

---

This quote from Thoreau’s _Walden_ seems relevant to the age of AI:

> Where is this division [or outsourcing] of [one’s personal] labor to end? and what object does it finally serve? No doubt another may also think for me; but it is not therefore desirable that he should do so to the exclusion of my thinking for myself.

Outsourcing thinking to AI is just the last frontier in a long tradition of debatably-virtuous outsourcing of hard things that give life meaning.

---

I’ve interviewed software engineering job applicants who basically couldn’t code at all without AI, and increasingly I see that people can’t write without it. Sometimes I have this perception that the pre-AI "boat" to learning things deeply has left the harbor, and students from now on just miss out on that. I’m hoping I’m wrong there and that AI Luddism is as hype-skewed as AI optimism is, but we’ll see.

---

I think there will be three groups of software engineers going forward:
- People who can’t code/reason deeply and who rely on AI to do it instead
- People who can code/reason deeply and stubbornly don’t use AI
- People who can code/reason deeply and are open enough to learn how best to use AI to work faster, but are careful enough to not let it think for them.

I suspect there will be a small to medium sized skill/performance gap between the second and third groups, and a _massive_ gap between the first and the second.

---

There’s a subdomain of coding tasks that ChatGPT (on GPT-4o especially) is well suited to: one-off file manipulation scripts. I think it’s because they’re short-lived; run by a human who can intervene if necessary; written in older, well-established languages; and built around well-understood operations like filesystem manipulation and simple network calls.

For example, I used GPT-4o to create a script to take a set of product image files and group them into Markdown files that contain the title and all the images for each product. Without ChatGPT, writing the script by hand would definitely have been doable, but it probably would have been faster to just do the work manually. But with ChatGPT, writing the script was definitely the faster route.

---

A prediction I made in a conversation with my wife back in mid-2022 (which I really should have written on my blog so I’d have a permalink): people will start to see generative AI the way they ought to see God---such as seeing it as a guide for making personal decisions and prioritization. Lends a whole new meaning to "making god in man’s image" or Paul’s warning of how in the last days people would "heap to themselves teachers, having itching ears" (2 Tim. 4:3)

